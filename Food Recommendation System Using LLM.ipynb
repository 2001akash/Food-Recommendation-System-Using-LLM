{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8850240,"sourceType":"datasetVersion","datasetId":5327184}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\nimport torch\n\n# Load the dataset\nfile_path = '/kaggle/input/recommend-dishes-on-mood/recommended_dishes_large.csv'\ndataset = pd.read_csv(file_path)\n\n# Convert 'Weight' column to numerical values\nweight_mapping = {'Light': 0, 'Moderate': 1, 'Heavy': 2}\ndataset['Weight'] = dataset['Weight'].map(weight_mapping)\n\n# Prepare training data with mood-based prompts\nmood_map = ['happy', 'sad', 'stressed', 'relaxed']\n\ntraining_data = []\nfor _, row in dataset.iterrows():\n    natural_prompt = f\"I want a dish for when I am feeling {mood_map[row['Mood']]}\"\n    output_text = f\"Dish: {row['DishName']}\"\n    training_data.append({\"input\": natural_prompt, \"output\": output_text})\n\n# Ensure the training data is diverse and balanced\n# Optional: You can shuffle the dataset to ensure randomness\nimport random\nrandom.shuffle(training_data)\n\n# Tokenize the data\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\ninput_texts = [item['input'] for item in training_data]\noutput_texts = [item['output'] for item in training_data]\n\ninputs = tokenizer(input_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\noutputs = tokenizer(output_texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n\n# Shift the labels for teacher forcing\nlabels = outputs[\"input_ids\"]\nlabels[labels == tokenizer.pad_token_id] = -100  # Replace padding token id's with -100\n\n# Create PyTorch dataset\nclass DishesDataset(torch.utils.data.Dataset):\n    def __init__(self, input_encodings, labels):\n        self.input_encodings = input_encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.input_encodings[\"input_ids\"])\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.input_encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\ndataset = DishesDataset(inputs, labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:00.678425Z","iopub.execute_input":"2024-07-10T15:43:00.679051Z","iopub.status.idle":"2024-07-10T15:43:01.128735Z","shell.execute_reply.started":"2024-07-10T15:43:00.679013Z","shell.execute_reply":"2024-07-10T15:43:01.127685Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    overwrite_output_dir=True,\n    num_train_epochs=10,  # Increased epochs for better training\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n    prediction_loss_only=True,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\"),\n    args=training_args,\n    train_dataset=dataset,\n)\n\n# Fine-tune the model\ntrainer.train()\n\n# Save the model and tokenizer\ntrainer.save_model(\"/kaggle/working/fine-tuned-bart-dishes\")\ntokenizer.save_pretrained(\"/kaggle/working/fine-tuned-bart-dishes\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:08.316617Z","iopub.execute_input":"2024-07-10T15:43:08.317186Z","iopub.status.idle":"2024-07-10T15:44:50.681898Z","shell.execute_reply.started":"2024-07-10T15:43:08.317157Z","shell.execute_reply":"2024-07-10T15:44:50.680734Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/3488644574.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item = {key: torch.tensor(val[idx]) for key, val in self.input_encodings.items()}\n/tmp/ipykernel_34/3488644574.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  item[\"labels\"] = torch.tensor(self.labels[idx])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1130' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1130/1130 01:37, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.887400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.522600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine-tuned-bart-dishes/tokenizer_config.json',\n '/kaggle/working/fine-tuned-bart-dishes/special_tokens_map.json',\n '/kaggle/working/fine-tuned-bart-dishes/vocab.json',\n '/kaggle/working/fine-tuned-bart-dishes/merges.txt',\n '/kaggle/working/fine-tuned-bart-dishes/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\n\n# Load the tokenizer and model\ntokenizer = BartTokenizer.from_pretrained(\"/kaggle/working/fine-tuned-bart-dishes\")\nmodel = BartForConditionalGeneration.from_pretrained(\"/kaggle/working/fine-tuned-bart-dishes\")\n\n# Function to generate a recommendation from a mood-based prompt\ndef generate_recommendation(natural_prompt):\n    input_ids = tokenizer.encode(natural_prompt, return_tensors=\"pt\")\n    outputs = model.generate(input_ids, max_length=50, num_return_sequences=1)\n    recommendation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return recommendation\n\n# Example inputs\nsample_inputs = [\n    \"I want a dish for when I am feeling happy\",\n    \"I want a dish for when I am feeling sad\",\n    \"I want a dish for when I am feeling stressed\",\n    \"I want a dish for when I am feeling relaxed\"\n]\n\nfor sample_input in sample_inputs:\n    recommendation = generate_recommendation(sample_input)\n    print(f\"Prompt: {sample_input} \\nRecommended Dish: {recommendation}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:47:35.810828Z","iopub.execute_input":"2024-07-10T15:47:35.811224Z","iopub.status.idle":"2024-07-10T15:47:38.604944Z","shell.execute_reply.started":"2024-07-10T15:47:35.811193Z","shell.execute_reply":"2024-07-10T15:47:38.602921Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Prompt: I want a dish for when I am feeling happy \nRecommended Dish: Dish: Pani Puri\n\nPrompt: I want a dish for when I am feeling sad \nRecommended Dish: Dish: Gongura Pachadi\n\nPrompt: I want a dish for when I am feeling stressed \nRecommended Dish: Dish: Neer Dosa\n\nPrompt: I want a dish for when I am feeling relaxed \nRecommended Dish: Dish: Masor Tenga\n\n","output_type":"stream"}]}]}